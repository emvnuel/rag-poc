quarkus.swagger-ui.always-include=true
quarkus.smallrye-openapi.path=/openapi
mp.openapi.extensions.smallrye.info.title=RAG SaaS API
mp.openapi.extensions.smallrye.info.version=1.0.0
mp.openapi.extensions.smallrye.info.description=API for RAG SaaS application

# Allow unmapped configuration properties (legacy lightrag.* properties)
smallrye.config.mapping.validate-unknown=false

quarkus.rest-client."llm-embedding".url=${LLM_EMBEDDING_URL:http://localhost:11434}
quarkus.rest-client."llm-embedding".read-timeout=2147483647
quarkus.rest-client."llm-embedding".connect-timeout=2147483647
quarkus.rest-client."llm-embedding".logging.scope=request-response
quarkus.rest-client."llm-embedding".logging.body-limit=8192
llm-embedding.api-key=${LLM_EMBEDDING_API_KEY:}
embedding.model=${EMBEDDING_MODEL:nomic-embed-text}

document.processor.batch.size=${DOCUMENT_PROCESSOR_BATCH_SIZE:10}

# Document processor scheduler configuration
# Use "off" to disable the scheduler
document.processor.schedule.marking=${DOCUMENT_PROCESSOR_SCHEDULE_MARKING:10s}
document.processor.schedule.processing=${DOCUMENT_PROCESSOR_SCHEDULE_PROCESSING:5s}

# Increase worker thread blocking timeout for long-running embedding API calls
quarkus.vertx.max-worker-execute-time=5m

quarkus.rest-client."llm-chat".url=${LLM_CHAT_URL:http://localhost:11434}
quarkus.rest-client."llm-chat".read-timeout=2147483647
quarkus.rest-client."llm-chat".connect-timeout=2147483647
quarkus.rest-client."llm-chat".logging.scope=request-response
quarkus.rest-client."llm-chat".logging.body-limit=8192
llm-chat.api-key=${LLM_CHAT_API_KEY:}

chat.model=${CHAT_MODEL:llama3.2}
chat.temperature=${CHAT_TEMPERATURE:0.7}
chat.max.tokens=${CHAT_MAX_TOKENS:2048}
chat.top.p=${CHAT_TOP_P:1.0}
chat.system.prompt=${CHAT_SYSTEM_PROMPT:You are a helpful assistant that answers questions based on the provided context.}
chat.system.prompt.no.context=${CHAT_SYSTEM_PROMPT_NO_CONTEXT:You are a helpful assistant. No specific context is available for this query.}

# File upload size limits
quarkus.http.limits.max-body-size=50M
quarkus.http.body.handle-file-uploads=true
quarkus.http.body.uploads-directory=${java.io.tmpdir}/quarkus-uploads

# CORS configuration
quarkus.http.cors.enabled=true
quarkus.http.cors.origins=*
quarkus.http.cors.methods=GET,POST,PUT,DELETE,OPTIONS,PATCH
quarkus.http.cors.headers=accept,authorization,content-type,x-requested-with
quarkus.http.cors.exposed-headers=*
quarkus.http.cors.access-control-max-age=24H
quarkus.http.cors.access-control-allow-credentials=true

# LightRAG Configuration
lightrag.vector.table.name=${LIGHTRAG_VECTOR_TABLE_NAME:lightrag_vectors}
# Vector dimension - MUST match your embedding model output dimension
# Default 768 matches nomic-embed-text (default EMBEDDING_MODEL)
# Common values: 384 (MiniLM), 768 (nomic-embed-text), 1536 (OpenAI), 3072 (text-embedding-3-large)
lightrag.vector.dimension=${LIGHTRAG_VECTOR_DIMENSION:768}

# Vector Index Configuration (aligned with official LightRAG Python implementation)
# Index type: hnsw (default, better recall) or ivfflat (better for very large datasets)
lightrag.vector.index.type=${LIGHTRAG_VECTOR_INDEX_TYPE:hnsw}
# HNSW parameters: m=connections per node, ef_construction=build search width
# Higher values = better recall, more memory/build time
lightrag.vector.index.hnsw.m=${LIGHTRAG_VECTOR_INDEX_HNSW_M:16}
lightrag.vector.index.hnsw.ef-construction=${LIGHTRAG_VECTOR_INDEX_HNSW_EF_CONSTRUCTION:64}
# IVFFLAT parameters: lists=number of clusters (sqrt(n) to n/1000 recommended)
lightrag.vector.index.ivfflat.lists=${LIGHTRAG_VECTOR_INDEX_IVFFLAT_LISTS:100}

lightrag.chunk.size=${LIGHTRAG_CHUNK_SIZE:1200}
lightrag.chunk.overlap=${LIGHTRAG_CHUNK_OVERLAP:100}
lightrag.query.top.k=${LIGHTRAG_QUERY_TOP_K:10}
lightrag.query.chunk.top.k=${LIGHTRAG_QUERY_CHUNK_TOP_K:5}
lightrag.storage.working.dir=${LIGHTRAG_STORAGE_WORKING_DIR:./lightrag-data}
lightrag.query.mode=${LIGHTRAG_QUERY_MODE:hybrid}

# LightRAG Concurrency Controls
# Maximum concurrent LLM API calls (prevents thread exhaustion)
lightrag.llm.max.concurrent.calls=${LIGHTRAG_LLM_MAX_CONCURRENT_CALLS:10}
# Number of chunks to process in parallel within each batch for entity extraction
lightrag.kg.extraction.batch.size=${LIGHTRAG_KG_EXTRACTION_BATCH_SIZE:20}
# Number of chunks to batch together for embedding API calls
lightrag.embedding.batch.size=${LIGHTRAG_EMBEDDING_BATCH_SIZE:32}

# LightRAG Entity Description Merging
# Maximum length for accumulated entity descriptions (prevents excessive storage)
lightrag.entity.description.max.length=${LIGHTRAG_ENTITY_DESCRIPTION_MAX_LENGTH:1000}
# Separator used when concatenating multiple descriptions
lightrag.entity.description.separator=${LIGHTRAG_ENTITY_DESCRIPTION_SEPARATOR: | }

# LightRAG Query System Prompts
lightrag.query.system.prompt.local=${LIGHTRAG_LOCAL_CHAT_SYSTEM_PROMPT:You are a helpful assistant. Use the following entity information to answer the question.}
lightrag.query.system.prompt.global=${LIGHTRAG_GLOBAL_CHAT_SYSTEM_PROMPT:You are a helpful assistant. Use the following relationship information to answer the question.}
lightrag.query.system.prompt.hybrid=${LIGHTRAG_HYBRID_CHAT_SYSTEM_PROMPT:You are a helpful assistant. Use the following entity and relationship information to answer the question.}
lightrag.query.system.prompt.naive=${LIGHTRAG_NAIVE_CHAT_SYSTEM_PROMPT:You are a helpful assistant. Use the following text chunks to answer the question.}
lightrag.query.system.prompt.mix=${LIGHTRAG_MIX_CHAT_SYSTEM_PROMPT:You are a helpful assistant. Use all available context to answer the question.}
lightrag.query.system.prompt.bypass=${LIGHTRAG_BYPASS_CHAT_SYSTEM_PROMPT:You are a helpful assistant.}
lightrag.entity.extraction.system.prompt=${LIGHTRAG_ENTITY_EXTRACTION_SYSTEM_PROMPT:Extract entities and relationships from the following text.}
lightrag.entity.types=${LIGHTRAG_ENTITY_TYPES:organization,person,location,event,concept}
lightrag.extraction.language=${LIGHTRAG_EXTRACTION_LANGUAGE:English}
lightrag.entity.extraction.user.prompt=${LIGHTRAG_ENTITY_EXTRACTION_USER_PROMPT:Please extract all entities and their relationships from the text above.}

# Entity Resolution Configuration
# Feature toggle for semantic entity deduplication
lightrag.entity.resolution.enabled=${LIGHTRAG_ENTITY_RESOLUTION_ENABLED:true}

# Similarity threshold for considering entities as duplicates [0.0, 1.0]
# Higher = more conservative (fewer merges), Lower = more aggressive (more merges)
# Recommended: 0.70-0.75 (literary texts), 0.75-0.80 (news), 0.80-0.85 (academic)
lightrag.entity.resolution.similarity.threshold=${LIGHTRAG_ENTITY_RESOLUTION_THRESHOLD:0.75}

# Maximum number of aliases to store per entity
lightrag.entity.resolution.max.aliases=${LIGHTRAG_ENTITY_RESOLUTION_MAX_ALIASES:5}

# Clustering algorithm: "threshold" (connected components) or "dbscan"
lightrag.entity.resolution.clustering.algorithm=${LIGHTRAG_ENTITY_RESOLUTION_CLUSTERING:threshold}

# Similarity Metric Weights (must sum to 1.0)
# Jaccard: token overlap matching (e.g., "Warren Home" vs "Warren State Home")
lightrag.entity.resolution.weight.jaccard=${LIGHTRAG_ENTITY_RESOLUTION_WEIGHT_JACCARD:0.35}
# Containment: substring matching (e.g., "MIT" vs "Massachusetts Institute of Technology")
lightrag.entity.resolution.weight.containment=${LIGHTRAG_ENTITY_RESOLUTION_WEIGHT_CONTAINMENT:0.25}
# Edit distance: character-level similarity (handles typos)
lightrag.entity.resolution.weight.edit=${LIGHTRAG_ENTITY_RESOLUTION_WEIGHT_EDIT:0.30}
# Abbreviation: acronym matching (e.g., "IBM" vs "International Business Machines")
lightrag.entity.resolution.weight.abbreviation=${LIGHTRAG_ENTITY_RESOLUTION_WEIGHT_ABBREV:0.10}

# Performance Tuning
# Batch size for processing entities (larger = more memory, faster processing)
lightrag.entity.resolution.batch.size=${LIGHTRAG_ENTITY_RESOLUTION_BATCH_SIZE:200}
# Enable parallel processing for similarity computation
lightrag.entity.resolution.parallel.enabled=${LIGHTRAG_ENTITY_RESOLUTION_PARALLEL_ENABLED:true}
# Number of threads for parallel processing
lightrag.entity.resolution.parallel.threads=${LIGHTRAG_ENTITY_RESOLUTION_PARALLEL_THREADS:4}

# Phase 3 - Semantic Similarity (OPTIONAL - disabled by default)
# Uses entity embeddings for description-based semantic matching
lightrag.entity.resolution.semantic.enabled=${LIGHTRAG_ENTITY_RESOLUTION_SEMANTIC_ENABLED:false}
# Weight for semantic similarity in combined score (only used if semantic.enabled=true)
lightrag.entity.resolution.semantic.weight=${LIGHTRAG_ENTITY_RESOLUTION_SEMANTIC_WEIGHT:0.40}

# Logging Configuration
# Log entity merge decisions at INFO level
lightrag.entity.resolution.log.merges=${LIGHTRAG_ENTITY_RESOLUTION_LOG_MERGES:true}
# Log detailed similarity scores at DEBUG level (verbose)
lightrag.entity.resolution.log.similarity.scores=${LIGHTRAG_ENTITY_RESOLUTION_LOG_SCORES:false}

# Database Configuration
# Disable Quarkus Dev Services (we use docker-compose for PostgreSQL)
quarkus.devservices.enabled=false

# PostgreSQL connection (using docker-compose container)
quarkus.datasource.db-kind=postgresql
quarkus.datasource.username=postgres
quarkus.datasource.password=postgres
quarkus.datasource.jdbc.url=jdbc:postgresql://localhost:5432/ragsaas

# Use 'none' since we manage schema via SQL init scripts in Docker
quarkus.hibernate-orm.database.generation=none
quarkus.hibernate-orm.schema-generation.create-schemas=false
# Set default schema for Hibernate ORM
quarkus.hibernate-orm.database.default-schema=rag

# REST Client Logging
quarkus.log.category."org.jboss.resteasy.reactive.client".level=DEBUG
quarkus.log.category."br.edu.ifba.chat.LlmChatClient".level=DEBUG
quarkus.log.category."br.edu.ifba.chat.LlmChatClientExceptionMapper".level=DEBUG
quarkus.log.category."br.edu.ifba.document.LlmEmbeddingClient".level=DEBUG
quarkus.log.category."br.edu.ifba.lightrag.adapters.QuarkusEmbeddingAdapter".level=DEBUG
quarkus.log.category."br.edu.ifba.lightrag.storage.impl.AgeGraphStorage".level=DEBUG

# =============================================================================
# Retry Configuration (SmallRye Fault Tolerance)
# =============================================================================
# Documentation: https://quarkus.io/guides/smallrye-fault-tolerance

# Global retry defaults for storage operations
# Max attempts: initial + retries (3 retries = 4 total attempts)
retry/maxRetries=3

# Exponential backoff: starts at 200ms, doubles each attempt
# Attempt 1: 0ms, Attempt 2: 200ms, Attempt 3: 400ms, Attempt 4: 800ms
retry/delay=200
retry/delayUnit=MILLIS
retry/maxDuration=30000
retry/durationUnit=MILLIS

# Jitter to prevent thundering herd (Â±20% of delay)
retry/jitter=200
retry/jitterDelayUnit=MILLIS

# Enable fault tolerance logging for observability
quarkus.log.category."io.smallrye.faulttolerance".level=INFO
quarkus.log.category."br.edu.ifba.lightrag.utils.RetryEventLogger".level=INFO

# =============================================================================
# LightRAG Extraction Configuration (Official Implementation Alignment)
# =============================================================================
# Documentation: specs/006-lightrag-official-impl/

# Gleaning Configuration - Iterative extraction for missed entities
# Enable iterative gleaning passes after initial extraction
lightrag.gleaning.enabled=${LIGHTRAG_GLEANING_ENABLED:true}
# Maximum number of gleaning passes (0 to disable, 1 is official default)
lightrag.gleaning.max-passes=${LIGHTRAG_GLEANING_MAX_PASSES:1}

# Description Summarization Configuration
# Maximum tokens for accumulated entity descriptions
lightrag.description.max-tokens=${LIGHTRAG_DESCRIPTION_MAX_TOKENS:500}
# Token threshold to trigger LLM summarization (should be < max-tokens)
lightrag.description.summarization-threshold=${LIGHTRAG_DESCRIPTION_SUMMARIZATION_THRESHOLD:300}
# Separator for concatenating descriptions below threshold
lightrag.description.separator=${LIGHTRAG_DESCRIPTION_SEPARATOR: | }

# Query Keyword Extraction Configuration
# Enable LLM-based keyword extraction for query routing
lightrag.query.keyword-extraction.enabled=${LIGHTRAG_QUERY_KEYWORD_EXTRACTION_ENABLED:true}
# Cache TTL for keyword extraction results (seconds)
lightrag.query.keyword-extraction.cache-ttl=${LIGHTRAG_QUERY_KEYWORD_EXTRACTION_CACHE_TTL:3600}

# Query Context Token Budget Configuration
# Maximum tokens for combined query context
lightrag.query.context.max-tokens=${LIGHTRAG_QUERY_CONTEXT_MAX_TOKENS:4000}
# Fraction of budget for entity context (local/hybrid modes)
lightrag.query.context.entity-budget-ratio=${LIGHTRAG_QUERY_CONTEXT_ENTITY_RATIO:0.4}
# Fraction of budget for relation context (global/hybrid modes)
lightrag.query.context.relation-budget-ratio=${LIGHTRAG_QUERY_CONTEXT_RELATION_RATIO:0.3}
# Fraction of budget for chunk context (mix/naive modes)
lightrag.query.context.chunk-budget-ratio=${LIGHTRAG_QUERY_CONTEXT_CHUNK_RATIO:0.3}

# Entity Name Normalization Configuration
# Maximum character length for entity names (truncated if exceeded)
lightrag.entity.name-max-length=${LIGHTRAG_ENTITY_NAME_MAX_LENGTH:500}
# Maximum source chunk IDs to track per entity (FIFO eviction)
lightrag.entity.max-source-ids=${LIGHTRAG_ENTITY_MAX_SOURCE_IDS:50}

# =============================================================================
# LightRAG Enhancements (spec-007)
# =============================================================================

# Reranker Configuration
# Enable/disable reranking for retrieved chunks
lightrag.rerank.enabled=${LIGHTRAG_RERANK_ENABLED:false}
# Provider: cohere, jina, none (default: none)
lightrag.rerank.provider=${LIGHTRAG_RERANK_PROVIDER:none}
# Minimum relevance score threshold (chunks below this are filtered)
lightrag.rerank.min-score=${LIGHTRAG_RERANK_MIN_SCORE:0.1}
# Timeout in milliseconds before falling back to original order
lightrag.rerank.fallback-timeout-ms=${LIGHTRAG_RERANK_FALLBACK_TIMEOUT_MS:2000}

# Cohere Reranker Settings
quarkus.rest-client."cohere-rerank".url=https://api.cohere.ai
quarkus.rest-client."cohere-rerank".read-timeout=3000
quarkus.rest-client."cohere-rerank".connect-timeout=2000
lightrag.rerank.cohere.api-key=${COHERE_API_KEY:}
lightrag.rerank.cohere.model=${COHERE_RERANK_MODEL:rerank-english-v3.0}

# Jina Reranker Settings
quarkus.rest-client."jina-rerank".url=https://api.jina.ai
quarkus.rest-client."jina-rerank".read-timeout=3000
quarkus.rest-client."jina-rerank".connect-timeout=2000
lightrag.rerank.jina.api-key=${JINA_API_KEY:}
lightrag.rerank.jina.model=${JINA_RERANK_MODEL:jina-reranker-v2-base-multilingual}

# Description Summarization (Map-Reduce) Configuration
# Skip summarization if fewer than this many descriptions
lightrag.description.force-summary-count=${LIGHTRAG_DESCRIPTION_FORCE_SUMMARY_COUNT:6}
# Skip summarization if total tokens below this threshold
lightrag.description.summary-context-size=${LIGHTRAG_DESCRIPTION_SUMMARY_CONTEXT_SIZE:10000}
# Max tokens per batch in map phase
lightrag.description.summary-max-tokens=${LIGHTRAG_DESCRIPTION_SUMMARY_MAX_TOKENS:500}
# Maximum map-reduce iterations (prevents infinite loops)
lightrag.description.max-map-iterations=${LIGHTRAG_DESCRIPTION_MAX_MAP_ITERATIONS:3}

# Chunk Selection Configuration
# Method: vector (similarity-based) or weight (occurrence-based)
lightrag.query.chunk-selection-method=${LIGHTRAG_QUERY_CHUNK_SELECTION_METHOD:vector}
# Maximum related chunks to include in context
lightrag.query.max-related-chunks=${LIGHTRAG_QUERY_MAX_RELATED_CHUNKS:20}

# Export Configuration
# Batch size for streaming export (larger = faster, more memory)
lightrag.export.batch-size=${LIGHTRAG_EXPORT_BATCH_SIZE:1000}

# =============================================================================
# SQLite Storage Backend Configuration (spec-009)
# =============================================================================
# Enable SQLite storage backend (overrides PostgreSQL when set)
# Options: postgresql (default), sqlite
lightrag.storage.backend=${LIGHTRAG_STORAGE_BACKEND:postgresql}

# SQLite Database Configuration
# Path to SQLite database file (relative to working directory or absolute)
lightrag.storage.sqlite.path=${LIGHTRAG_SQLITE_PATH:data/rag.db}

# Path to native extension libraries (if not bundled in JAR)
# Leave empty to use bundled extensions
lightrag.storage.sqlite.extensions.path=${LIGHTRAG_SQLITE_EXTENSIONS_PATH:}

# SQLite Connection Pool Configuration
# Number of read connections in pool (SQLite supports concurrent reads)
lightrag.storage.sqlite.read-pool-size=${LIGHTRAG_SQLITE_READ_POOL_SIZE:4}

# Busy timeout in milliseconds (how long to wait for locks)
lightrag.storage.sqlite.busy-timeout=${LIGHTRAG_SQLITE_BUSY_TIMEOUT:30000}

# Enable WAL mode for concurrent reads (recommended)
lightrag.storage.sqlite.wal-mode=${LIGHTRAG_SQLITE_WAL_MODE:true}

# SQLite cache size in KB (negative = KB, positive = pages)
lightrag.storage.sqlite.cache-size=${LIGHTRAG_SQLITE_CACHE_SIZE:-64000}

# SQLite Vector Configuration
# Vector type: FLOAT32, FLOAT16, BFLOAT16, INT8, UINT8
lightrag.storage.sqlite.vector.type=${LIGHTRAG_SQLITE_VECTOR_TYPE:FLOAT32}

# Distance metric: L2, COSINE, DOT, L1
lightrag.storage.sqlite.vector.distance=${LIGHTRAG_SQLITE_VECTOR_DISTANCE:COSINE}

# =============================================================================
# Code Source RAG Configuration (spec-010)
# =============================================================================

# Code Document Extraction
# Enable code file processing (auto-detects CODE document type)
lightrag.code.extraction.enabled=${LIGHTRAG_CODE_EXTRACTION_ENABLED:true}

# Binary file detection
# Number of bytes to check for binary content detection (magic bytes + NUL frequency)
lightrag.code.binary.check.size=${LIGHTRAG_CODE_BINARY_CHECK_SIZE:8192}

# Code-specific chunking (integrated in LightRAG.processDocument)
# When document type is CODE, uses CodeChunker which respects function/class boundaries
# Falls back to default TokenUtil.chunkText() for non-code documents
# Uses same chunk size/overlap settings as general documents (lightrag.chunk.size, lightrag.chunk.overlap)

# Code-specific entity types (used when DocumentType.CODE is detected)
# These types replace the default entity types during code extraction
# 
# Expanded semantic entity types covering:
# - Code structure: function, class, module, interface, package, namespace, method, constructor
# - Type system: type, generic_type, type_alias, enum, union_type, struct, trait, protocol
# - Data & state: variable, field, property, constant, parameter, global_variable, static_variable
# - Architecture: api_endpoint, service, component, controller, repository, middleware, handler
# - Dependencies: dependency, library, framework, external_api, database_schema
# - Design patterns: singleton, factory, observer, decorator, adapter, strategy
# - Concurrency: thread, process, coroutine, async_function, lock, semaphore
# - Error handling: exception, error_type, error_handler
# - Testing: test_case, test_suite, mock, fixture
# - Documentation: annotation, decorator, attribute, pragma, directive
# - Security: authentication, authorization, encryption, validation, sanitization
# - Configuration: config_parameter, environment_variable, feature_flag
# - Performance: cache, optimization, profiler, benchmark
lightrag.entity.types.code=${LIGHTRAG_CODE_ENTITY_TYPES:function,method,constructor,class,abstract_class,interface,module,package,namespace,type,generic_type,type_alias,enum,union_type,struct,trait,protocol,variable,field,property,constant,parameter,global_variable,static_variable,api_endpoint,rest_endpoint,grpc_endpoint,graphql_endpoint,service,component,controller,repository,model,view,middleware,handler,dependency,library,framework,external_api,database_schema,table,collection,singleton,factory,observer,decorator,adapter,strategy,builder,thread,process,coroutine,async_function,callback,promise,lock,semaphore,mutex,exception,error_type,error_handler,test_case,test_suite,mock,fixture,annotation,decorator_function,attribute,pragma,directive,authentication,authorization,encryption,validation,sanitization,config_parameter,environment_variable,feature_flag,cache,optimization,algorithm,data_structure}

# Code relationship types (automatically used for CODE documents)
# Includes code-specific relationships like calls, imports, inheritance, implementation
lightrag.relationship.types.code=${LIGHTRAG_CODE_RELATIONSHIP_TYPES:calls,imports,inherits,implements,depends_on,uses,defined_in,exports,references,throws,returns,overrides,extends,contains,invokes,instantiates,configures,subscribes_to,publishes,handles,triggers}

# Language Detection
# Automatic language detection from file extensions (Java, Python, JS, TS, Go, Rust, C, C++, C#, etc.)
# Detected language is passed to extraction prompts for language-aware entity extraction

# Code Extraction Prompts
# System prompt for code entity extraction (supports placeholders: {entity_types}, {relationship_types}, {language})
lightrag.code.extraction.system.prompt=${LIGHTRAG_CODE_EXTRACTION_SYSTEM_PROMPT:You are an expert code analyzer. Extract entities and relationships from source code. Focus on: {entity_types}. Language: {language}. Return JSON with 'entities' and 'relationships' arrays.}
# User prompt for code extraction (supports placeholder: {input_text})
lightrag.code.extraction.user.prompt=${LIGHTRAG_CODE_EXTRACTION_USER_PROMPT:Source code to analyze:\n\n{input_text}\n\nPlease extract all entities and relationships following the guidelines above.}

# =============================================================================
# Git Repository Ingestion Configuration
# =============================================================================

# Git clone base directory (where repositories are temporarily cloned)
git.clone.base.dir=${GIT_CLONE_BASE_DIR:./git-repos}

# Git clone timeout in seconds (prevents hanging on large repositories)
git.clone.timeout.seconds=${GIT_CLONE_TIMEOUT_SECONDS:300}

# Maximum file size to process in MB (files larger than this are skipped)
git.max.file.size.mb=${GIT_MAX_FILE_SIZE_MB:10}
